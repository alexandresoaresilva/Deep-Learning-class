{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array([[0,0,1],\\\n",
    "#               [0,1,1],\\\n",
    "#               [1,0,1],\\\n",
    "#               [1,1,1]], dtype=np.float32)#1 appended in the last column is the bias\n",
    "\n",
    "# t = { #dictionary for getting both the target logic values and the correlated string \n",
    "#     \"AND\":  np.array([[0], \n",
    "#                       [0],\n",
    "#                       [0],\n",
    "#                       [1]], dtype=np.float32),\n",
    "    \n",
    "#     \"NAND\": np.array([[1],\n",
    "#                       [1],\n",
    "#                       [1],\n",
    "#                       [0]], dtype=np.float32),\n",
    "    \n",
    "#     \"OR\":   np.array([[0], \n",
    "#                       [1],\n",
    "#                       [1],\n",
    "#                       [1]], dtype=np.float32),\n",
    "    \n",
    "#     \"NOR\":  np.array([[1],\n",
    "#                       [1],\n",
    "#                       [1],\n",
    "#                       [0]], dtype=np.float32),\n",
    "    \n",
    "#     \"XOR\":  np.array([[0],\n",
    "#                       [1],\n",
    "#                       [1],\n",
    "#                       [0]], dtype=np.float32) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,0,1],\\\n",
    "              [0,1,1],\\\n",
    "              [1,0,1],\\\n",
    "              [1,1,1]], dtype=np.float32)#1 appended in the last column is the bias\n",
    "\n",
    "t = { #dictionary for getting both the target logic values and the correlated string \n",
    "    \"AND\":  np.array([[-1], \n",
    "                      [-1],\n",
    "                      [-1],\n",
    "                      [1]], dtype=np.float32),\n",
    "    \n",
    "    \"NAND\": np.array([[1],\n",
    "                      [1],\n",
    "                      [1],\n",
    "                      [-1]], dtype=np.float32),\n",
    "    \n",
    "    \"OR\":   np.array([[-1], \n",
    "                      [1],\n",
    "                      [1],\n",
    "                      [1]], dtype=np.float32),\n",
    "    \n",
    "    \"NOR\":  np.array([[1],\n",
    "                      [1],\n",
    "                      [1],\n",
    "                      [-1]], dtype=np.float32),\n",
    "    \n",
    "    \"XOR\":  np.array([[-1],\n",
    "                      [1],\n",
    "                      [1],\n",
    "                      [-1]], dtype=np.float32) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function definitions\n",
    "y_pred, online_perceptron are correct. Not sure about cost.\n",
    "The nested for loop is terrible, I know. It was a required part of the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is 4 x3 and w is 3x1 \n",
    "def cost(y,x,w):\n",
    "    return y.T@X@w\n",
    "\n",
    "def online_perceptron(X, t, rho, epochs, gate_name=\"\"):\n",
    "    y = np.array([0, 0, 0, 0], dtype=np.float32)\n",
    "    w_k = np.array([.5, .5, .5], dtype=np.float32)\n",
    "    converged = False\n",
    "    \n",
    "    time_to_show = np.round(np.linspace(0,epochs, 40))\n",
    "    \n",
    "    k = 0\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        for j in range(len(X)):\n",
    "             #zeros in [w_k, 0,...] is so that function selects the right w vector\n",
    "            y[j] = y_pred(X[j,:], [w_k, 0, 0, 0])\n",
    "            err = t[j] - y[j]\n",
    "            w_k = w_k + rho*err*X[j,:]\n",
    "            \n",
    "        if len(y.shape) < 2: #make it a column vector if it is a flat array\n",
    "            y = y.reshape(y.shape[0],1)\n",
    "        if np.array_equal(y,t):\n",
    "            converged = True\n",
    "            break\n",
    "            \n",
    "#         if i == time_to_show[k]:\n",
    "#             cost_w = cost(y, X, w_k.reshape(w_k.shape[0],1))\n",
    "#             print(\"cost: \" + str(cost_w))\n",
    "#             k +=1\n",
    "    \n",
    "    w_pkg = [w_k.reshape(w_k.shape[0],1), converged, i+1, epochs, rho]\n",
    "#     print(\"TRAIN PREDICTION >>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "#     y_pred(X, w_pkg,gate_name=gate_name,\\\n",
    "#            use_step_prediction=False, print_result=True)    \n",
    "#     print(\"= end of perceptron ============================\")\n",
    "    \n",
    "    return w_pkg\n",
    "\n",
    "def y_pred(X, w_pckg, gate_name=\"No gate loaded\",\\\n",
    "           use_step_prediction=False, print_result=False):\n",
    "    # w_pckg[0]: w vector\n",
    "    # w_pckg[1]: converged or not (True or False)\n",
    "    # w_pckg[2]: no. of iterations to converge\n",
    "    # w_pckg[3]: max no. of iterations\n",
    "    # w_pckg[4]: learning rate\n",
    "    y = X @ w_pckg[0] # 0 or 1 for output\n",
    "\n",
    "    y = np.sign(y)\n",
    "    \n",
    "    if print_result:\n",
    "        print(gate_name+ \":\")\n",
    "        print(np.heaviside(y.reshape(y.shape[0],1),0))\n",
    "        if w_pckg[3]:\n",
    "            print(str(w_pckg[2]) + \" iterations to convergence\")\n",
    "        else:\n",
    "            print(\"did not converge\")\n",
    "        print(str(w_pckg[3]) + \" (max iterations)\")\n",
    "        print(str(w_pckg[4]) + \" (learning rate)\")\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs for loops for all logic gate within the dictionary t\n",
    "# for one learning rate AND a one no. of epochs\n",
    "def predict_percept_all_gates(X, t, rho, epochs):\n",
    "    \n",
    "    w_pkg = {}\n",
    "    for i in t:     # online_perceptron(X, t, rho, epochs, gate_name=\"\")\n",
    "        w_pkg[i] = online_perceptron(X, t[i], rho, epochs, gate_name=i)\n",
    "    \n",
    "    y_p = {}\n",
    "    k = 0\n",
    "\n",
    "    for i in t: #\n",
    "#         y_pred(X, w_pckg, gate_name=\"No gate loaded\", use_step_prediction=False, print_result=False):\n",
    "        y_p[i] = y_pred(X, w_pkg[i], gate_name=i, print_result=True)\n",
    "        print()\n",
    "        k += 1\n",
    "        \n",
    "    return [y_p, w_pkg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== learning rate: 1e-04 =============================\n",
      "AND:\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "1390 iterations to convergence\n",
      "40000 (max iterations)\n",
      "1e-04 (learning rate)\n",
      "\n",
      "NAND:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "2506 iterations to convergence\n",
      "40000 (max iterations)\n",
      "1e-04 (learning rate)\n",
      "\n",
      "OR:\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "2501 iterations to convergence\n",
      "40000 (max iterations)\n",
      "1e-04 (learning rate)\n",
      "\n",
      "NOR:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "2506 iterations to convergence\n",
      "40000 (max iterations)\n",
      "1e-04 (learning rate)\n",
      "\n",
      "XOR:\n",
      "[[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "40000 iterations to convergence\n",
      "40000 (max iterations)\n",
      "1e-04 (learning rate)\n",
      "\n",
      "===== learning rate: 0.001 =============================\n",
      "AND:\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "140 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.001 (learning rate)\n",
      "\n",
      "NAND:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "256 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.001 (learning rate)\n",
      "\n",
      "OR:\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "251 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.001 (learning rate)\n",
      "\n",
      "NOR:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "256 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.001 (learning rate)\n",
      "\n",
      "XOR:\n",
      "[[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "40000 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.001 (learning rate)\n",
      "\n",
      "===== learning rate: 0.01 =============================\n",
      "AND:\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "15 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "NAND:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "31 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "OR:\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "26 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "NOR:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "31 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "XOR:\n",
      "[[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "40000 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "===== learning rate: 0.01 =============================\n",
      "AND:\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "15 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "NAND:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "31 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "OR:\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "26 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "NOR:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "31 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "XOR:\n",
      "[[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "40000 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "===== learning rate: 0.1 =============================\n",
      "AND:\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "5 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.1 (learning rate)\n",
      "\n",
      "NAND:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "5 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.1 (learning rate)\n",
      "\n",
      "OR:\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "4 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.1 (learning rate)\n",
      "\n",
      "NOR:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "5 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.1 (learning rate)\n",
      "\n",
      "XOR:\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "40000 iterations to convergence\n",
      "40000 (max iterations)\n",
      "0.1 (learning rate)\n",
      "\n",
      "===== learning rate: 1.0 =============================\n",
      "AND:\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "6 iterations to convergence\n",
      "40000 (max iterations)\n",
      "1.0 (learning rate)\n",
      "\n",
      "NAND:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "6 iterations to convergence\n",
      "40000 (max iterations)\n",
      "1.0 (learning rate)\n",
      "\n",
      "OR:\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "4 iterations to convergence\n",
      "40000 (max iterations)\n",
      "1.0 (learning rate)\n",
      "\n",
      "NOR:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "6 iterations to convergence\n",
      "40000 (max iterations)\n",
      "1.0 (learning rate)\n",
      "\n",
      "XOR:\n",
      "[[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "40000 iterations to convergence\n",
      "40000 (max iterations)\n",
      "1.0 (learning rate)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = {}\n",
    "\n",
    "# y: dictionary; to access members, use an element of the list RHO\n",
    "# e.g. y[RHO[0]] == [y_pred, w_pkg], a list with a dict y_pred AND a dict the w_pkg \n",
    "#                                  y_pred: dict with 5 elements (indeces are the logic gates' names, capital letters)\n",
    "#                                          each one a logic gate's prediction\n",
    "#                                  w_pkg: dict with 5 elements (same indexing as y_pred)\n",
    "#                                          each one a list with the the following elements:\n",
    "#                                               [w_k, no_of_iterations_to_convergence, epochs, converged, rho]\n",
    "#                                               [3-element np array(w vect), scalar, scalar, scalar, scalar]\n",
    "\n",
    "#learning reates\n",
    "RHO = np.array([.0001,.001,.01,.01,.1,1], dtype=np.float32)\n",
    "#epochs\n",
    "iterations = [200, 2_000, 20_000, 40_000]\n",
    "\n",
    "for i in range(len(RHO)):\n",
    "    print(\"===== learning rate: \" + str(RHO[i]) + \" =============================\")\n",
    "    y[RHO[i]] = predict_percept_all_gates(X, t, RHO[i], iterations[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example on first rho, y_pred selected, XOR\n",
    "np.heaviside(y[RHO[0]][0][\"XOR\"],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-9ab3a014413a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'w1' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
