{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from numpy import zeros, ones, eye\n",
    "import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,0,1],\\\n",
    "              [0,1,1],\\\n",
    "              [1,0,1],\\\n",
    "              [1,1,1]], dtype=np.float32)#1 appended in the last column is the bias\n",
    "\n",
    "t = { #dictionary for getting both the target logic values and the correlated string \n",
    "    \"AND\": np.array([0, 0, 0, 1], dtype=np.float32),\n",
    "    \"NAND\": np.array([1, 1, 1, 0], dtype=np.float32),\n",
    "    \"OR\": np.array([0, 1, 1, 1], dtype=np.float32),\n",
    "    \"NOR\": np.array([1, 0, 0, 0], dtype=np.float32),\n",
    "    \"XOR\": np.array([0, 1, 1, 0], dtype=np.float32) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function definitions\n",
    "y_pred, online_perceptron are correct. Not sure about cost.\n",
    "The nested for loop is terrible, I know. It was a required part of the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y,x,w):\n",
    "    J = y*x*w\n",
    "    print(y*x*w)\n",
    "    return J\n",
    "\n",
    "def y_pred(X, w_pckg, gate_name, print_result):\n",
    "    # w_pckg[0]: w vector\n",
    "    # w_pckg[1]: no. of iterations to converge\n",
    "    # w_pckg[2]: max no. of iterations\n",
    "    # w_pckg[3]: converged or not (1 or 0)\n",
    "    # w_pckg[4]: learning rate\n",
    "    \n",
    "    y = np.heaviside(X @ w_pckg[0], 0) # 0 or 1 for output\n",
    "    if print_result:\n",
    "        print(gate_name + \": \" + str(y))\n",
    "        if w_pckg[3]:\n",
    "            print(str(w_pckg[1]) + \" iterations to convergence\")\n",
    "        else:\n",
    "            print(\"did not converge\")\n",
    "        print(str(w_pckg[2]) + \" (max iterations)\")\n",
    "        print(str(w_pckg[4]) + \" (learning rate)\")\n",
    "    return y\n",
    "\n",
    "def online_perceptron(X, t, rho, epochs):\n",
    "    y = np.array([0, 0, 0, 0], dtype=np.float32)\n",
    "    w_k = np.array([0, 0, 0], dtype=np.float32)\n",
    "    converged = 0\n",
    "    for i in range(epochs):            \n",
    "        for j in range(len(X)):\n",
    "             #zeros in [w_k, 0,...] is so that function selects the right w vector\n",
    "            y[j] = y_pred(X[j,:], [w_k, 0, 0, 0], '', 0) \n",
    "            err = t[j] - y[j]\n",
    "            w_k = w_k + rho*err*X[j,:]\n",
    "            \n",
    "        #it stops once all are matching\n",
    "        if len(np.where(t == y)[0]) == 4:\n",
    "            converged = 1\n",
    "            break\n",
    "    return [w_k, i+1, epochs, converged, rho]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs for loops for all logic gate within the dictionary t\n",
    "# for one learning rate AND a one no. of epochs\n",
    "def predict_percept_all_gates(X, t, rho, epochs):\n",
    "    w_pkg = {}\n",
    "    for i in t:\n",
    "        w_pkg[i] = online_perceptron(X, t[i], rho, epochs)\n",
    "    \n",
    "    y_p = {}\n",
    "    k = 0\n",
    "\n",
    "    for i in t: #\n",
    "        y_p[i] = y_pred(X, w_pkg[i], i, 1)\n",
    "        print()\n",
    "        k += 1\n",
    "        \n",
    "    return [y_p, w_pkg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== learning rate: 1e-04 =============================\n",
      "AND: [0. 0. 0. 1.]\n",
      "6 iterations to convergence\n",
      "200 (max iterations)\n",
      "1e-04 (learning rate)\n",
      "\n",
      "NAND: [1. 1. 1. 0.]\n",
      "6 iterations to convergence\n",
      "200 (max iterations)\n",
      "1e-04 (learning rate)\n",
      "\n",
      "OR: [0. 1. 1. 1.]\n",
      "4 iterations to convergence\n",
      "200 (max iterations)\n",
      "1e-04 (learning rate)\n",
      "\n",
      "NOR: [1. 0. 0. 0.]\n",
      "4 iterations to convergence\n",
      "200 (max iterations)\n",
      "1e-04 (learning rate)\n",
      "\n",
      "XOR: [1. 1. 0. 0.]\n",
      "did not converge\n",
      "200 (max iterations)\n",
      "1e-04 (learning rate)\n",
      "\n",
      "===== learning rate: 0.001 =============================\n",
      "AND: [0. 0. 0. 1.]\n",
      "6 iterations to convergence\n",
      "200 (max iterations)\n",
      "0.001 (learning rate)\n",
      "\n",
      "NAND: [1. 1. 1. 0.]\n",
      "6 iterations to convergence\n",
      "200 (max iterations)\n",
      "0.001 (learning rate)\n",
      "\n",
      "OR: [0. 1. 1. 1.]\n",
      "4 iterations to convergence\n",
      "200 (max iterations)\n",
      "0.001 (learning rate)\n",
      "\n",
      "NOR: [1. 0. 0. 0.]\n",
      "4 iterations to convergence\n",
      "200 (max iterations)\n",
      "0.001 (learning rate)\n",
      "\n",
      "XOR: [1. 1. 0. 0.]\n",
      "did not converge\n",
      "200 (max iterations)\n",
      "0.001 (learning rate)\n",
      "\n",
      "===== learning rate: 0.01 =============================\n",
      "AND: [0. 0. 0. 1.]\n",
      "6 iterations to convergence\n",
      "200 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "NAND: [1. 1. 1. 0.]\n",
      "6 iterations to convergence\n",
      "200 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "OR: [0. 1. 1. 1.]\n",
      "4 iterations to convergence\n",
      "200 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "NOR: [1. 0. 0. 0.]\n",
      "4 iterations to convergence\n",
      "200 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "XOR: [1. 1. 0. 0.]\n",
      "did not converge\n",
      "200 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "===== learning rate: 0.01 =============================\n",
      "AND: [0. 0. 0. 1.]\n",
      "6 iterations to convergence\n",
      "200 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "NAND: [1. 1. 1. 0.]\n",
      "6 iterations to convergence\n",
      "200 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "OR: [0. 1. 1. 1.]\n",
      "4 iterations to convergence\n",
      "200 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "NOR: [1. 0. 0. 0.]\n",
      "4 iterations to convergence\n",
      "200 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "XOR: [1. 1. 0. 0.]\n",
      "did not converge\n",
      "200 (max iterations)\n",
      "0.01 (learning rate)\n",
      "\n",
      "===== learning rate: 0.1 =============================\n",
      "AND: [0. 0. 0. 1.]\n",
      "6 iterations to convergence\n",
      "200 (max iterations)\n",
      "0.1 (learning rate)\n",
      "\n",
      "NAND: [1. 1. 1. 0.]\n",
      "4 iterations to convergence\n",
      "200 (max iterations)\n",
      "0.1 (learning rate)\n",
      "\n",
      "OR: [0. 1. 1. 1.]\n",
      "4 iterations to convergence\n",
      "200 (max iterations)\n",
      "0.1 (learning rate)\n",
      "\n",
      "NOR: [1. 0. 0. 0.]\n",
      "4 iterations to convergence\n",
      "200 (max iterations)\n",
      "0.1 (learning rate)\n",
      "\n",
      "XOR: [1. 1. 0. 0.]\n",
      "did not converge\n",
      "200 (max iterations)\n",
      "0.1 (learning rate)\n",
      "\n",
      "===== learning rate: 1.0 =============================\n",
      "AND: [0. 0. 0. 1.]\n",
      "6 iterations to convergence\n",
      "200 (max iterations)\n",
      "1.0 (learning rate)\n",
      "\n",
      "NAND: [1. 1. 1. 0.]\n",
      "6 iterations to convergence\n",
      "200 (max iterations)\n",
      "1.0 (learning rate)\n",
      "\n",
      "OR: [0. 1. 1. 1.]\n",
      "4 iterations to convergence\n",
      "200 (max iterations)\n",
      "1.0 (learning rate)\n",
      "\n",
      "NOR: [1. 0. 0. 0.]\n",
      "4 iterations to convergence\n",
      "200 (max iterations)\n",
      "1.0 (learning rate)\n",
      "\n",
      "XOR: [1. 1. 0. 0.]\n",
      "did not converge\n",
      "200 (max iterations)\n",
      "1.0 (learning rate)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = {}\n",
    "\n",
    "# y: dictionary; to access members, use an element of the list RHO\n",
    "# e.g. y[RHO[0]] == [y_pred, w_pkg], a list with a dict y_pred AND a dict the w_pkg \n",
    "#                                  y_pred: dict with 5 elements (indeces are the logic gates' names, capital letters)\n",
    "#                                          each one a logic gate's prediction\n",
    "#                                  w_pkg: dict with 5 elements (same indexing as y_pred)\n",
    "#                                          each one a list with the the following elements:\n",
    "#                                               [w_k, no_of_iterations_to_convergence, epochs, converged, rho]\n",
    "#                                               [3-element np array(w vect), scalar, scalar, scalar, scalar]\n",
    "\n",
    "#learning reates\n",
    "RHO = np.array([.0001,.001,.01,.01,.1,1], dtype=np.float32)\n",
    "#epochs\n",
    "iterations = [200, 2_000, 20_000, 200_000, 2_000_000]\n",
    "\n",
    "for i in range(len(RHO)):\n",
    "    print(\"===== learning rate: \" + str(RHO[i]) + \" =============================\")\n",
    "    y[RHO[i]] = predict_percept_all_gates(X, t, RHO[i], iterations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example on first rho, y_pred selected, XOR\n",
    "y[RHO[0]][0][\"NAND\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
