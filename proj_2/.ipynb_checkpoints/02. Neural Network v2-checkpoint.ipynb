{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cost/activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y,y_hat):\n",
    "    return 1/2*np.sum( np.power(y - y_hat, 2) )\n",
    "\n",
    "def logistic_sigmoid(x, derivative=0):\n",
    "    sigm = 1/(1 + np.exp(-x))\n",
    "    \n",
    "    if derivative:\n",
    "        return sigm*(1. - sigm)\n",
    "    \n",
    "    return sigm\n",
    "\n",
    "# from https://deepnotes.io/softmax-crossentropy\n",
    "def stable_softmax(a, derivative=0):\n",
    "    exps = np.exp(a - np.max(a))\n",
    "\n",
    "    if len(exps.shape) > 1:\n",
    "        ans = np.zeros((exps.shape[0],2))\n",
    "        numerator = exps.sum(axis=1).reshape((exps.shape[0], 1))\n",
    "        numerator = np.append(numerator, numerator, axis=1)\n",
    "    else:\n",
    "#         ans = np.zeros((exps.shape[0],))\n",
    "        ans = np.zeros((2,2))\n",
    "        numerator = np.sum(exps)\n",
    "        \n",
    "    S = exps/numerator\n",
    "    \n",
    "    if derivative:\n",
    "        if len(exps.shape) > 1: # for more than one sample\n",
    "            for i in range(exps.shape[0]):\n",
    "                ans[i, 0] = S[i, 1]*(1 - S[i, 0])\n",
    "                ans[i, 1] = S[i, 0]*(1 - S[i, 1])\n",
    "        else:\n",
    "            kro_delta = 0\n",
    "            for i in range(ans.shape[0]):\n",
    "                for j in range(ans.shape[1]):                        \n",
    "                    if i==j:\n",
    "                        kro_delta = 1\n",
    "                    else:\n",
    "                        kro_delta = 0\n",
    "                        \n",
    "                    ans[i,j] = S[i]*(kro_delta - S[j])\n",
    "                        \n",
    "#                     ans[i,j] = S[0]*(1-S[1])\n",
    "#                     \n",
    "# ans[1] = S[1]*(1-S[0])\n",
    "\n",
    "#                     ans[0] = S[0]*(1-S[1])\n",
    "#                     ans[1] = S[1]*(1-S[0])\n",
    "#             ans[1] = -S[0]*S[1]\n",
    "#             ans[1] = S[0]*(1-S[1])\n",
    "#             ans[1] = -S[0]*S[1]\n",
    "        return ans\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    A1 = (X @ W1 + b1)[0]\n",
    "    Z1 = logistic_sigmoid(A1) \n",
    "    A2 = (Z1 @ W2 + b2)[0]\n",
    "    Y = stable_softmax(A2)\n",
    "    return A1, A2, Y\n",
    "\n",
    "def backprop(W2, A1, A2, X, Y, t):\n",
    "    \n",
    "    ## mid layer\n",
    "    # 2 x 1\n",
    "    step1 = (t - Y) @ -stable_softmax(A2, derivative=1)\n",
    "    \n",
    "    # 1 X N hidden units\n",
    "    step2 = logistic_sigmoid(A1, derivative=1)\n",
    "    step2 = step2.reshape(1,step2.shape[0])\n",
    "    # N x 1\n",
    "    step3 = W2\n",
    "#     step3 = step3.reshape(step3.shape[0],1)\n",
    "    \n",
    "    grad_mid_layer = X.T @ step1 @ step2 @ step3\n",
    "    \n",
    "    ## output layer (first step has been calculated already)\n",
    "    step1 = step1.reshape(step1.shape[0],1)\n",
    "    # 1 X N hidden units\n",
    "    \n",
    "    step2 = logistic_sigmoid(A1, derivative=0)\n",
    "    N_no_hid_units = step2.shape[0]\n",
    "    \n",
    "    step2 = step2.reshape(1, N_no_hid_units)\n",
    "    \n",
    "    grad_output = step1 @ step2\n",
    "    \n",
    "#     grad_mid_layer = ((t-Y) @ -stable_softmax(A2, derivative=1)).T @ logistic_sigmoid(A1, derivative=1) @ W2 @ X.T\n",
    "#     grad_output = ((t-Y) @ -stable_softmax(A2, derivative=1)).T @ logistic_sigmoid(A1, derivative=0) \n",
    "    \n",
    "#     grad_output = grad_output @ np.eye(N_no_hid_units,M=1)\n",
    "\n",
    "    return grad_mid_layer, grad_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset / targets\n",
    "X: possible inputs of a logic function.\n",
    "t: dictionary with possible outputs for each logic gates. \n",
    "    4 binary ouputs to match NN's output probabilities of 0 or 1. \n",
    "    - if [p(0) p(1)] == [1 0] then probability of 0 == 1 && probability of 1 == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,0],\\\n",
    "              [0,1],\\\n",
    "              [1,0],\\\n",
    "              [1,1]], dtype=np.float32)\n",
    "\n",
    "t = { #dictionary for getting both the target logic values and the correlated string \n",
    "    # binary labels to represent the probabilities of 1 or 0 (first column is 0, 2nd 1)\n",
    "    \"AND\": np.array([[1, 0],\\\n",
    "                     [1, 0],\\\n",
    "                     [1, 0],\\\n",
    "                     [0, 1]], dtype=np.float32),\n",
    "    \n",
    "    \"NAND\": np.array([[0, 1],\\\n",
    "                      [0, 1],\\\n",
    "                      [0, 1],\\\n",
    "                      [1, 0]], dtype=np.float32),\n",
    "    \n",
    "    \"OR\": np.array([[1, 0],\\\n",
    "                    [0, 1],\\\n",
    "                    [0, 1],\\\n",
    "                    [0, 1]], dtype=np.float32),\n",
    "    \n",
    "    \"NOR\": np.array([[0, 1],\\\n",
    "                     [1, 0],\\\n",
    "                     [1, 0],\\\n",
    "                     [1, 0]], dtype=np.float32),\n",
    "    \n",
    "    \"XOR\": np.array([[1, 0],\\\n",
    "                     [0, 1],\\\n",
    "                     [0, 1],\\\n",
    "                     [1, 0]], dtype=np.float32) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14429549, -0.03058221],\n",
       "       [-0.03058221,  0.14429549]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stable_softmax(t[\"AND\"][1,:].reshape((1,2)))\n",
    "# stable_softmax(t[\"AND\"][0,:],derivative=1)\n",
    "stable_softmax(t[\"AND\"][:,1],derivative=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generating weights and biases\n",
    "no. of hidden units in the second layer is defined here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_UNITS_L1 = 4\n",
    "\n",
    "W1 = np.random.randn(2, NO_UNITS_L1)\n",
    "b1 = np.zeros((1, NO_UNITS_L1))\n",
    "W2 = np.random.randn(NO_UNITS_L1, 2) # 2 outputs, P(0) and P(1)\n",
    "b2 = np.zeros((1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### running the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6541730248524862\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,4) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-b73c077c704a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mW1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mW1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mrho\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrad_mid_layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mW2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mW2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mrho\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrad_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mrho\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_mid_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,4) (2,) "
     ]
    }
   ],
   "source": [
    "rho = .001\n",
    "T = t[\"OR\"]\n",
    "\n",
    "for i in range(30_000):\n",
    "    for j in range(X.shape[0]):\n",
    "        A1, A2, Y = forward_prop(W1, b1, W2, b2, X[j,:])\n",
    "        \n",
    "        grad_mid_layer, grad_output = backprop(W2, A1, A2, X[j,:], Y, T[j,:])\n",
    "        \n",
    "        print(cost(T[j,:],Y))\n",
    "        \n",
    "        W1 = W1 - rho*grad_mid_layer\n",
    "        W2 = W2 - rho*grad_output.T\n",
    "        b1 = b1 - rho*np.mean(grad_mid_layer)\n",
    "        b2 = b2 - rho*np.mean(grad_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: [0. 1.]\n",
      "Y: [0.01189078 0.98810922]\n"
     ]
    }
   ],
   "source": [
    "test = 1\n",
    "A1, A2, Y = forward_prop(W1, b1, W2, b2, X[test,:])\n",
    "\n",
    "print(\"t: \" + str(T[test,:]))\n",
    "print(\"Y: \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1, A2, Y = forward_prop(W1, b1, W2, b2, X[1,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = 1\n",
    "# # A1, A2, Y = forward_prop(W1, b1, W2, b2, X[1,:])\n",
    "\n",
    "# 2 x 1\n",
    "step1 = (t[\"OR\"][test,:] - Y) @ -stable_softmax(A2, derivative=1)\n",
    "step1 = step1.reshape(step1.shape[0],1)\n",
    "# 1 X N hidden units\n",
    "step2 = logistic_sigmoid(A1, derivative=0)\n",
    "step2 = step2.reshape(1,step2.shape[0])\n",
    "\n",
    "step1 @ step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.03760353,  1.7403077 , -0.03290419, -0.18653771],\n",
       "       [-1.65769565, -0.81123515, -0.11098208,  0.16165617]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1\n",
    "# grad_mid_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.97711749, -0.01575291])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stable_softmax(A2, derivative=0)\n",
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_mid_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
