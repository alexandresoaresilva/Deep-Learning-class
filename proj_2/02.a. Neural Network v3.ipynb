{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cost/activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost(y[1,:].reshape(1,2),y_hat[1,:].reshape(1,2), derivative=0)\n",
    "def cost(y,y_hat, derivative=0):\n",
    "    if derivative:\n",
    "            return np.sum(y - y_hat, axis=0)\n",
    "    return 1/2*np.sum(np.power(y - y_hat, 2),\\\n",
    "                     axis=0)\n",
    "\n",
    "def logistic_sigmoid(x, derivative=0):\n",
    "    \n",
    "    sigm = 1/(1 + np.exp(-x))\n",
    "    if len(sigm.shape) < 2:\n",
    "        sigm = sigm.reshape(sigm.shape[0],1)\n",
    "        \n",
    "    if derivative:\n",
    "        return sigm*(1. - sigm)\n",
    "    return sigm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN functions 1\n",
    "BACKEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>> init_weights_biases >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# W1, b1, W2, b2 = init_weights_biases(no_hidden_units=8)\n",
    "def init_weights_biases(no_hidden_units=2, seed=1):\n",
    "    #all vectors are column vectors\n",
    "    np.random.seed(seed) #shown to converge for other XOR regression problem\n",
    "    \n",
    "    W1 = np.random.randn(no_hidden_units, 2)\n",
    "    \n",
    "    b1 = np.zeros((no_hidden_units, 1))\n",
    "    W2 = np.random.randn(2, no_hidden_units) # 2 outputs, P(0) and P(1)\n",
    "    b2 = np.zeros((2, 1))\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# W1, b1, W2, b2 = init_weights_biases(no_hidden_units=8)\n",
    "# A1, A2, Y = forward_prop(W1, b1, W2, b2, X)\n",
    "# >>>>>>>>>>>>>>>>>>> forward_prop >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    x = X.T\n",
    "\n",
    "    if len(x.shape) < 2:\n",
    "        no_of_samples = 1\n",
    "        x = x.reshape(x.shape[0],1)\n",
    "    else:\n",
    "        no_of_samples = x.shape[0]\n",
    "\n",
    "    Z2 = W1 @ x  + b1\n",
    "    A2 = logistic_sigmoid(Z2)  # second layer)\n",
    "    Z3 = W2 @ A2 + b2\n",
    "    A3 = logistic_sigmoid(Z3)\n",
    "\n",
    "    Y = np.zeros((no_of_samples,2))\n",
    "\n",
    "    #scaling to making the pair a probability\n",
    "    Y = np.divide(A3, np.sum(A3, axis=0)) #comuns are the samples now\n",
    "    return Z2, Z3, Y\n",
    "\n",
    "# W1, b1, W2, b2 = init_weights_biases(no_hidden_units=8)\n",
    "# A1, A2, Y = forward_prop(W1, b1, W2, b2, X)\n",
    "# grad_mid_layer, grad_output = backprop(W2, A1, A2, X, Y, t)\n",
    "# backprop(W2, A1, A2, X, Y, t)\n",
    "# >>>>>>>>>>>>>>>>>>> backprop >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "def backprop(W2, Z2, Z3, X, Y_hat, t):\n",
    "    if len(X.shape) < 2:\n",
    "        X = X.reshape(1,X.shape[0])\n",
    "  ########  gradient W1    \n",
    "    op1 = ( -(t.T - Y_hat ) * logistic_sigmoid(Z3, derivative=1)) #gets 6x4 matrix\n",
    "    op2 = W2.T @ op1 \n",
    "    op3 = op2 * logistic_sigmoid(Z2, derivative=1) # @ 6 x 4 still\n",
    "    del_W1 = op3 @ X # 6x2\n",
    "    \n",
    "  ########  gradient W2\n",
    "    step2 = logistic_sigmoid(Z2, derivative=0) #just A2\n",
    "    del_W2 = op1 @ step2.T\n",
    "    \n",
    "    return del_W1, del_W2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN functions 2\n",
    "frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>> train >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "#online (sample by sample) training\n",
    "# all samples (X), 4 x 2, are fed\n",
    "def train(X, T, epochs, learning_rate,\\\n",
    "          NO_UNITS_L1=4, show_cost=0):\n",
    "    \n",
    "    converged = False\n",
    "    rho = learning_rate\n",
    "    Y = np.zeros((2,X.shape[0])) # 4 x 2 always (the whole dataset is fed)\n",
    "    \n",
    "    W1, b1, W2, b2 = init_weights_biases(no_hidden_units=NO_UNITS_L1)\n",
    "    \n",
    "    rho = 1\n",
    "    show_cost = 0\n",
    "    W1, b1, W2, b2 = init_weights_biases(no_hidden_units=8)\n",
    "    Y = np.zeros((X.shape[0], 2)) # 4 x 2 always (the whole dataset is fed)\n",
    "\n",
    "    j = 0\n",
    "    for i in range(epochs):\n",
    "        idx_done = i + 1\n",
    "        Z2, Z3, Y_hat = forward_prop(W1, b1, W2, b2, X)\n",
    "        grad_W1, graD_W2 = backprop(W2, Z2, Z3, X, Y_hat, T)\n",
    "\n",
    "        #grad descent\n",
    "        W1 = W1 - rho*grad_W1\n",
    "        W2 = W2 - rho*graD_W2\n",
    "\n",
    "        if show_cost:\n",
    "            print(\"cost: \" + str(cost(T,Y)))\n",
    "\n",
    "        Y = np.round(Y_hat).T\n",
    "        \n",
    "        y_and_T_match = np.array_equal(Y, T)        \n",
    "\n",
    "        if y_and_T_match: #converged\n",
    "            j += 1\n",
    "            if j > 1:\n",
    "                converged = True\n",
    "                break\n",
    "    \n",
    "    return [W1, b1, W2, b2, X, Y, idx_done, epochs, converged, rho]\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>> predict >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "#train package is a list with [W1, b1, W2, b2, X]\n",
    "# n: 0-3 selection of logical inputs; e.g. 0 == [0, 0]; 3 == [1,1]\n",
    "def predict(train_pkg):\n",
    "    Z2, Z3, Y = forward_prop(train_pkg[0], train_pkg[1],\\\n",
    "                             train_pkg[2], train_pkg[3], \\\n",
    "                             train_pkg[4])\n",
    "    del Z2, Z3\n",
    "    \n",
    "    return np.round(Y).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN functions 2 (helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>> train_all_gates >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "def train_all_gates(X, t, no_hidden_units=2,\\\n",
    "                    iterations=500, rho=.01, print_cost=0):\n",
    "    train_gates = {} #init dictionary\n",
    "\n",
    "    for i in t:\n",
    "        # NO_UNITS_L1 = 6  yields max matches with rho = 1 and epochs = 500\n",
    "#         train_gates[i] : [W1, b1, W2, b2, X, Y, idx_done, epochs, converged, rho]\n",
    "        train_gates[i] = train(X, t[i], NO_UNITS_L1=no_hidden_units,\\\n",
    "                               epochs=iterations, learning_rate=rho,\\\n",
    "                               show_cost=print_cost)\n",
    "    return train_gates\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>> match_logic_gate >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "def match_logic_gate(train_pkg, T):\n",
    "\n",
    "    Y = predict(train_pkg)\n",
    "    prediction_match = np.array_equal(Y, T)\n",
    "#         train_pkg : [W1, b1, W2, b2, X, Y, idx_done, epochs, converged, rho]\n",
    "    # indeces used, especially:\n",
    "    #                                 8. converged\n",
    "    #                                 6. idx_done, \n",
    "    #                                 7. epochs\n",
    "    #                                 9. rho\n",
    "    match_pkg = [train_pkg[8], train_pkg[6],\\\n",
    "                  train_pkg[7], train_pkg[9],\\\n",
    "                  prediction_match, Y]\n",
    "        \n",
    "    return match_pkg\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>> match_all_gate_outputs >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "def match_all_gate_outputs(train_pkg_all_gates, t):\n",
    "    matches = {}\n",
    "\n",
    "    for i in t:\n",
    "        matches[i] = match_logic_gate(train_pkg_all_gates[i], t[i])\n",
    "        \n",
    "    return matches\n",
    "\n",
    "def print_match(match):\n",
    "    print(i + \" converged: \" + str(match[0]))\n",
    "    print(\"===========================================\")\n",
    "    print(\"  iter. to converge: \" + str(match[1]))\n",
    "    print(\"  iter. max: \" + str(match[2]))\n",
    "    if match[4]:\n",
    "        print(\"  ==== CORRECT prediction ==== \")\n",
    "    else:\n",
    "        print(\"  ==== INCORRECT prediction ==== \")\n",
    "    print(\"  predicted y (y_hat): \")\n",
    "    print(match[5])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset / targets\n",
    "X: possible inputs of a logic function.\n",
    "t: dictionary with possible outputs for each logic gates. \n",
    "    4 binary ouputs to match NN's output probabilities of 0 or 1. \n",
    "    - if [p(0) p(1)] == [1 0] then probability of 0 == 1 && probability of 1 == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,0],\\\n",
    "              [0,1],\\\n",
    "              [1,0],\\\n",
    "              [1,1]], dtype=np.float32)\n",
    "\n",
    "t = { #dictionary for getting both the target logic values and the correlated string \n",
    "    # binary labels to represent the probabilities of 1 or 0 (first column is 0, 2nd 1)\n",
    "    \"AND\": np.array([[1, 0],\\\n",
    "                     [1, 0],\\\n",
    "                     [1, 0],\\\n",
    "                     [0, 1]], dtype=np.float32),\n",
    "    \n",
    "    \"NAND\": np.array([[0, 1],\\\n",
    "                      [0, 1],\\\n",
    "                      [0, 1],\\\n",
    "                      [1, 0]], dtype=np.float32),\n",
    "    \n",
    "    \"OR\": np.array([[1, 0],\\\n",
    "                    [0, 1],\\\n",
    "                    [0, 1],\\\n",
    "                    [0, 1]], dtype=np.float32),\n",
    "    \n",
    "    \"NOR\": np.array([[0, 1],\\\n",
    "                     [1, 0],\\\n",
    "                     [1, 0],\\\n",
    "                     [1, 0]], dtype=np.float32),\n",
    "    \n",
    "    \"XOR\": np.array([[1, 0],\\\n",
    "                     [0, 1],\\\n",
    "                     [0, 1],\\\n",
    "                     [1, 0]], dtype=np.float32) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### running the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pkg_all_gates = train_all_gates(X, t, no_hidden_units=10, iterations=1000, rho=1)\n",
    "matches = match_all_gate_outputs(train_pkg_all_gates, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matches\n",
    "matches is a Python dictionary. for ex: \n",
    "\n",
    "    matches[\"OR\"]\n",
    "    returns a list:\n",
    "            matches[\"OR\"][0] == boolean (converged or not, True or False)\n",
    "            matches[\"OR\"][1] == idx_done, no. of iterations to converge\n",
    "            matches[\"OR\"][2] == total iterations (epochs)\n",
    "            matches[\"OR\"][3] == learning rate used(rho)\n",
    "            matches[\"OR\"][4] == matches with target (comparing both p(0) and p(1))\n",
    "            matches[\"OR\"][5] == predicted Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND converged: True\n",
      "===========================================\n",
      "  iter. to converge: 22\n",
      "  iter. max: 1000\n",
      "  ==== CORRECT prediction ==== \n",
      "  predicted y (y_hat): \n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "\n",
      "NAND converged: True\n",
      "===========================================\n",
      "  iter. to converge: 27\n",
      "  iter. max: 1000\n",
      "  ==== CORRECT prediction ==== \n",
      "  predicted y (y_hat): \n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "\n",
      "OR converged: True\n",
      "===========================================\n",
      "  iter. to converge: 24\n",
      "  iter. max: 1000\n",
      "  ==== CORRECT prediction ==== \n",
      "  predicted y (y_hat): \n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "NOR converged: True\n",
      "===========================================\n",
      "  iter. to converge: 32\n",
      "  iter. max: 1000\n",
      "  ==== CORRECT prediction ==== \n",
      "  predicted y (y_hat): \n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "\n",
      "XOR converged: True\n",
      "===========================================\n",
      "  iter. to converge: 32\n",
      "  iter. max: 1000\n",
      "  ==== CORRECT prediction ==== \n",
      "  predicted y (y_hat): \n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in matches:\n",
    "    print_match(matches[i])\n",
    "    \n",
    "# predict(train_pkg_all_gates[\"XOR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR_pkg = train_pkg_all_gates[\"XOR\"]\n",
    "# Z2, Z3, Y = forward_prop(OR_pkg[0], OR_pkg[1],\\\n",
    "#                          OR_pkg[2], OR_pkg[3], \\\n",
    "#                          OR_pkg[4][2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0469975],\n",
       "       [0.9530025]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
